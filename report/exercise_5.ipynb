{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks \n",
    "- add analytical result for comparison with methods\n",
    "- for exercise (5 - 9) add comments and verify results\n",
    "- Insert picture of calculations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to generate a confidence interval given a vector of sampled values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCI(vals):\n",
    "    n = len(vals)\n",
    "    CL = 0.95 # confidence level\n",
    "    DF = n-1 # degrees of freedom\n",
    "    z = np.abs(stats.t.ppf((1-CL)/2,DF))\n",
    "    mean = np.mean(vals)\n",
    "    std = np.std(vals, ddof = 1)\n",
    "    u = mean + z*std/np.sqrt(n)\n",
    "    l = mean - z*std/np.sqrt(n)\n",
    "    return mean, l, u"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> (1) Estimate integral using crude Monte Carlo </h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sample 100 values from the uniform distribution and apply the crude method to get the estimate of the integral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance of the estimation is: 0.2321\n",
      "The estimate of the integral is: 1.6403\n",
      "With the following confidence interval: 1.5443, 1.7364\n"
     ]
    }
   ],
   "source": [
    "us = np.random.uniform(0,1, size = 100)\n",
    "exp = np.exp(us)\n",
    "print('The variance of the estimation is: {:.4f}'.format(np.var(exp)))\n",
    "mean, l, u = getCI(exp)\n",
    "print('The estimate of the integral is: {:.4f}'.format(mean))\n",
    "print('With the following confidence interval: {:.4f}, {:.4f}'.format(l,u))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> (2) Estimate integral using antithetic variables </h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sample 100 values from the uniform distribution and we estimate the integral using antithetic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance of the estimation is: 0.0042\n",
      "The estimate of the integral is: 1.7209\n",
      "With the following confidence interval: 1.7079, 1.7338\n"
     ]
    }
   ],
   "source": [
    "us = np.random.uniform(0,1, size = 100)\n",
    "exp = np.exp(us)\n",
    "y = (exp + np.e/exp)/2\n",
    "\n",
    "print('The variance of the estimation is: {:.4f}'.format(np.var(y)))\n",
    "mean, l, u = getCI(y)\n",
    "print('The estimate of the integral is: {:.4f}'.format(mean))\n",
    "print('With the following confidence interval: {:.4f}, {:.4f}'.format(l,u))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the variance is reduced a lot with respect to the crude method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> (3) Estimate integral using control variates </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance of the estimation is: 0.0030\n",
      "The estimate of the integral is: 1.7118\n",
      "With the following confidence interval: 1.7009, 1.7228\n"
     ]
    }
   ],
   "source": [
    "us = np.random.uniform(0,1, size = 100)\n",
    "exp = np.exp(us)\n",
    "c = -np.cov(exp, us)[0,1]/np.var(us)\n",
    "z = exp + c*(us - 1/2)\n",
    "print('The variance of the estimation is: {:.4f}'.format(np.var(z)))\n",
    "mean, l, u = getCI(z)\n",
    "print('The estimate of the integral is: {:.4f}'.format(mean))\n",
    "print('With the following confidence interval: {:.4f}, {:.4f}'.format(l,u))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also in this case the variance is reduced with respect the crude method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> (4) Estimate integral using stratified sampling </h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use stratified sampling with 10 strata to get the estimate of the integral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance of the estimation is: 0.0006\n",
      "The estimate of the integral is: 1.7258\n",
      "With the following confidence interval: 1.7076, 1.7441\n"
     ]
    }
   ],
   "source": [
    "w = [] # The final list will contain ten values for the estimation of the integral\n",
    "for i in range(10):\n",
    "    us = np.random.uniform(0,1,10) # Each sample is based on ten uniformly distributed values\n",
    "    w.append(np.sum([np.exp((j + us[j])/10) for j in range(10)])/10) # Stratified sampling\n",
    "\n",
    "print('The variance of the estimation is: {:.4f}'.format(np.var(w)))\n",
    "mean, l, u = getCI(w)\n",
    "print('The estimate of the integral is: {:.4f}'.format(mean))\n",
    "print('With the following confidence interval: {:.4f}, {:.4f}'.format(l,u))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> (5) Control variates for blocking queueing system simulation </h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "control variate is the mean arrival time for the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_queue(nserver, customers, mean_st, mean_tbc):\n",
    "    server_time = np.zeros(nserver)\n",
    "    time = 0\n",
    "    blocked = 0\n",
    "    t_arrival_time = 0\n",
    "    for _ in range(customers):\n",
    "        delta_arrival_time = stats.expon.rvs(scale = mean_tbc, size = 1)[0]\n",
    "        t_arrival_time += delta_arrival_time\n",
    "        time += delta_arrival_time\n",
    "        min_server = np.min(server_time)\n",
    "        idx_min_server = np.argmin(server_time)\n",
    "        if time < min_server:\n",
    "            blocked +=1\n",
    "        else:\n",
    "            delta_service_time = stats.expon.rvs(scale = mean_st, size = 1)\n",
    "            server_time[idx_min_server] = time + delta_service_time\n",
    "    \n",
    "    return blocked/customers, t_arrival_time/customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.12357379105435233, 0.12179769757319586, 0.1253498845355088)\n",
      "(0.12391, 0.11938588047557853, 0.12843411952442146)\n",
      "3.999655555555557e-05 6.164333011813146e-06\n"
     ]
    }
   ],
   "source": [
    "nserver = 10\n",
    "mean_st = 8\n",
    "mean_tbc = 1\n",
    "customers = 10000\n",
    "nsim = 10\n",
    "runs = []\n",
    "arrivals = []\n",
    "for i in range(nsim):\n",
    "    blocked, arrival = simulate_queue(nserver, customers, mean_st, mean_tbc)\n",
    "    runs.append(blocked)\n",
    "    arrivals.append(arrival)\n",
    "\n",
    "runs = np.array(runs)\n",
    "arrivals = np.array(arrivals)\n",
    "c = -np.cov(runs, arrivals)[0,1]/np.var(arrivals)\n",
    "z = runs + c*(arrivals - mean_tbc)\n",
    "print(getCI(z))\n",
    "print(getCI(runs))\n",
    "print(np.cov(runs), np.cov(z))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance is indeed reduced"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> (6) Common random numbers in queueing system simulation </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TtestResult(statistic=16.68412262034125, pvalue=4.462657602263568e-08, df=9),\n",
       " 16.684122620341252)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getExp(lam, us):\n",
    "    exp = -np.log(us)/lam\n",
    "    return exp \n",
    "\n",
    "def getHyperExp(p, lam1, lam2, u1, u2):\n",
    "    res = np.zeros(len(u1))\n",
    "    res[u2 <= p] = getExp(lam = lam1, us = u1[u2 <=p])\n",
    "    res[u2 > p] = getExp(lam = lam2, us = u1[u2 > p])\n",
    "    return res\n",
    "\n",
    "def simulate_queue_q2(nserver, customers, mean_st, mean_tbc, type = 'Exp', seed = 0):\n",
    "    np.random.seed(seed)\n",
    "    u1 = np.random.uniform(0,1, customers)\n",
    "    u2 = np.random.uniform(0,1, customers)\n",
    "    server_time = np.zeros(nserver)\n",
    "    time = 0\n",
    "    blocked = 0\n",
    "    if type == 'Exp':\n",
    "        arrival_times = getExp(lam = mean_tbc, us = u1)\n",
    "    elif type == 'Hyp':\n",
    "        arrival_times = getHyperExp(0.8, 0.8333, 5, u1, u2)\n",
    "    for i in range(customers):\n",
    "        delta_arrival_time = arrival_times[i]\n",
    "        time += delta_arrival_time\n",
    "        min_server = np.min(server_time)\n",
    "        idx_min_server = np.argmin(server_time)\n",
    "        if time < min_server:\n",
    "            blocked += 1\n",
    "        else:\n",
    "            server_time[idx_min_server] = time + stats.expon.rvs(scale = mean_st, size = 1)\n",
    "    \n",
    "    return blocked/customers\n",
    "\n",
    "nserver = 10\n",
    "mean_st = 8\n",
    "mean_tbc = 1\n",
    "customers = 10000\n",
    "nsim = 10\n",
    "runs = []\n",
    "for i in range(10):\n",
    "    runs.append([simulate_queue_q2(nserver, customers, mean_st, mean_tbc, 'Hyp', i), simulate_queue_q2(nserver, customers, mean_st, mean_tbc, 'Exp', i)])\n",
    "\n",
    "runs = np.array(runs)\n",
    "stats.ttest_rel(runs[:,0], runs[:,1]), np.mean(runs[:,0] - runs[:,1])*np.sqrt(10)/np.std(runs[:,0] - runs[:,1], ddof = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> (7) Monte Carlo on standard normal random variable </h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crude method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.022726, 0.022433908776859402, 0.023018091223140597)\n",
      "0.022726 0.02275013194817921\n"
     ]
    }
   ],
   "source": [
    "a = 2\n",
    "tot = 1000000\n",
    "values = np.random.randn(tot) > a\n",
    "res = np.mean(values)\n",
    "print(getCI(values))\n",
    "print(res, 1 - stats.norm.cdf(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importance sampling reduces the amount of samples required to estimate the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1981058435350963e-05 3.167124183311998e-05\n"
     ]
    }
   ],
   "source": [
    "a = 4\n",
    "s = 1\n",
    "tot = 10000\n",
    "\n",
    "samples = stats.norm.rvs(loc = a, scale = s, size = tot)\n",
    "\n",
    "h = samples > a\n",
    "f = stats.norm.pdf(samples)\n",
    "g = stats.norm.pdf(samples, loc = a, scale = s)\n",
    "\n",
    "Z = h * f / g\n",
    "res = np.mean(Z)\n",
    "\n",
    "#print(getCI(Z))\n",
    "print(res, 1 - stats.norm.cdf(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> (8) Exponential importance sampling </h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{l}\n",
    "g(x):=\\lambda \\cdot \\mathrm{e}^{-\\lambda \\cdot x}=x \\rightarrow \\lambda \\mathrm{e}^{-\\lambda x} \\\\\n",
    "h(x):=\\mathrm{e}^x=x \\rightarrow \\mathrm{e}^x \\\\\n",
    "\\operatorname{simplify}\\left(\\frac{h(x)}{g(x)}\\right) \\cdot f=\\frac{\\mathrm{e}^{x(\\lambda+1)} f}{\\lambda} \\\\\n",
    "E Z:=\\int_0^1 \\frac{\\mathrm{e}^{x(\\lambda+1)}}{\\lambda} \\cdot g(x) \\mathrm{d} x=-1+\\mathrm{e} \\\\\n",
    "E Z 2:=\\int_0^1\\left(\\frac{\\mathrm{e}^{x(\\lambda+1)}}{\\lambda}\\right)^2 \\cdot g(x) \\mathrm{d} x=\\frac{\\mathrm{e}^{\\lambda+2}-1}{(\\lambda+2) \\lambda} \\\\\n",
    "\\operatorname{Var}(\\lambda):=\\text { evalf }(E Z 2-E Z): \\\\\n",
    "\\text { fsolve }(\\operatorname{diff}(\\operatorname{Var}(\\lambda), \\lambda)=0, \\lambda, 0 . .5) \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "$$\n",
    "\\lambda = 1.354829\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.1349436524236687, 1.71996476377874)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam = 1.35483\n",
    "size = 100000\n",
    "values = stats.expon.rvs(scale = 1/lam, size = size)\n",
    "f = np.logical_and(values <= 1, values>=0)\n",
    "h = np.exp(values)\n",
    "g = lam*np.exp(-lam*values)\n",
    "\n",
    "res = f * h / g\n",
    "np.var(res), np.mean(res)\n",
    "\n",
    "# equal to the analytical solution (see photos on phone, done on paper)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> (9) Pareto IS estimator </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21.000000000000075, 20.999999999999982)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 1.05\n",
    "size = 10000\n",
    "values = stats.pareto.rvs(k-1, size = size)\n",
    "\n",
    "h = values\n",
    "f = stats.pareto.pdf(values, k)\n",
    "g = stats.pareto.pdf(values, k-1)\n",
    "\n",
    "res = h * f / g\n",
    "np.mean(res), k/(k-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
