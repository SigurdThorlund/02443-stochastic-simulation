{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to generate a confidence interval given a vector of sampled values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCI(vals):\n",
    "    n = len(vals)\n",
    "    CL = 0.95 # confidence level\n",
    "    DF = n-1 # degrees of freedom\n",
    "    z = np.abs(stats.t.ppf((1-CL)/2,DF))\n",
    "    mean = np.mean(vals)\n",
    "    std = np.std(vals, ddof = 1)\n",
    "    u = mean + z*std/np.sqrt(n)\n",
    "    l = mean - z*std/np.sqrt(n)\n",
    "    return mean, l, u"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 - crude method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sample 100 values from the uniform distribution and apply the crude method to get the estimate of the integral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance of the estimation is: 0.2421\n",
      "The estimate of the integral is: 1.7572\n",
      "With the following confidence interval: 1.6590, 1.8553\n"
     ]
    }
   ],
   "source": [
    "us = np.random.uniform(0,1, size = 100)\n",
    "exp = np.exp(us)\n",
    "print('The variance of the estimation is: {:.4f}'.format(np.var(exp)))\n",
    "mean, l, u = getCI(exp)\n",
    "print('The estimate of the integral is: {:.4f}'.format(mean))\n",
    "print('With the following confidence interval: {:.4f}, {:.4f}'.format(l,u))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2  - antithetic variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sample 100 values from the uniform distribution and we estimate the integral using antithetic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance of the estimation is: 0.0042\n",
      "The estimate of the integral is: 1.7154\n",
      "With the following confidence interval: 1.7024, 1.7283\n"
     ]
    }
   ],
   "source": [
    "us = np.random.uniform(0,1, size = 100)\n",
    "exp = np.exp(us)\n",
    "y = (exp + np.e/exp)/2\n",
    "\n",
    "print('The variance of the estimation is: {:.4f}'.format(np.var(y)))\n",
    "mean, l, u = getCI(y)\n",
    "print('The estimate of the integral is: {:.4f}'.format(mean))\n",
    "print('With the following confidence interval: {:.4f}, {:.4f}'.format(l,u))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the variance is reduced a lot with respect to the crude method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - control variates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance of the estimation is: 0.0039\n",
      "The estimate of the integral is: 1.7220\n",
      "With the following confidence interval: 1.7096, 1.7344\n"
     ]
    }
   ],
   "source": [
    "us = np.random.uniform(0,1, size = 100)\n",
    "exp = np.exp(us)\n",
    "c = -np.cov(exp, us)[0,1]/np.var(us)\n",
    "z = exp + c*(us - 1/2)\n",
    "print('The variance of the estimation is: {:.4f}'.format(np.var(z)))\n",
    "mean, l, u = getCI(z)\n",
    "print('The estimate of the integral is: {:.4f}'.format(mean))\n",
    "print('With the following confidence interval: {:.4f}, {:.4f}'.format(l,u))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also in this case the variance is reduced with respect the crude method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 - stratified sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use stratified sampling with 10 strata to get the estimate of the integral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance of the estimation is: 0.0003\n",
      "The estimate of the integral is: 1.7147\n",
      "With the following confidence interval: 1.7026, 1.7268\n"
     ]
    }
   ],
   "source": [
    "w = [] # The final list will contain ten values for the estimation of the integral\n",
    "for i in range(10):\n",
    "    us = np.random.uniform(0,1,10) # Each sample is based on ten uniformly distributed values\n",
    "    w.append(np.sum([np.exp((j + us[j])/10) for j in range(10)])/10) # Stratified sampling\n",
    "\n",
    "print('The variance of the estimation is: {:.4f}'.format(np.var(w)))\n",
    "mean, l, u = getCI(w)\n",
    "print('The estimate of the integral is: {:.4f}'.format(mean))\n",
    "print('With the following confidence interval: {:.4f}, {:.4f}'.format(l,u))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 - control variates for the queueing problem in Ex4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "control variate is the mean arrival time for the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_queue(nserver, customers, mean_st, mean_tbc):\n",
    "    server_time = np.zeros(nserver)\n",
    "    time = 0\n",
    "    blocked = 0\n",
    "    t_arrival_time = 0\n",
    "    for _ in range(customers):\n",
    "        delta_arrival_time = stats.expon.rvs(scale = mean_tbc, size = 1)[0]\n",
    "        t_arrival_time += delta_arrival_time\n",
    "        time += delta_arrival_time\n",
    "        min_server = np.min(server_time)\n",
    "        idx_min_server = np.argmin(server_time)\n",
    "        if time < min_server:\n",
    "            blocked +=1\n",
    "        else:\n",
    "            delta_service_time = stats.expon.rvs(scale = mean_st, size = 1)\n",
    "            server_time[idx_min_server] = time + delta_service_time\n",
    "    \n",
    "    return blocked/customers, t_arrival_time/customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.11989798911541467, 0.12168346526458784, 0.1181125129662415)\n",
      "(0.11982000000000001, 0.12178887107092433, 0.11785112892907569)\n",
      "7.575111111111105e-06 6.229634374080824e-06\n"
     ]
    }
   ],
   "source": [
    "nserver = 10\n",
    "mean_st = 8\n",
    "mean_tbc = 1\n",
    "customers = 10000\n",
    "nsim = 10\n",
    "runs = []\n",
    "arrivals = []\n",
    "for i in range(nsim):\n",
    "    blocked, arrival = simulate_queue(nserver, customers, mean_st, mean_tbc)\n",
    "    runs.append(blocked)\n",
    "    arrivals.append(arrival)\n",
    "\n",
    "runs = np.array(runs)\n",
    "arrivals = np.array(arrivals)\n",
    "c = -np.cov(runs, arrivals)[0,1]/np.var(arrivals)\n",
    "z = runs + c*(arrivals - mean_tbc)\n",
    "print(getCI(z))\n",
    "print(getCI(runs))\n",
    "print(np.cov(runs), np.cov(z))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance is indeed reduced"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# q6 - common random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Ttest_relResult(statistic=16.68412262034125, pvalue=4.462657602263569e-08),\n",
       " 16.684122620341252)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getExp(lam, us):\n",
    "    exp = -np.log(us)/lam\n",
    "    return exp \n",
    "\n",
    "def getHyperExp(p, lam1, lam2, u1, u2):\n",
    "    res = np.zeros(len(u1))\n",
    "    res[u2 <= p] = getExp(lam = lam1, us = u1[u2 <=p])\n",
    "    res[u2 > p] = getExp(lam = lam2, us = u1[u2 > p])\n",
    "    return res\n",
    "\n",
    "def simulate_queue_q2(nserver, customers, mean_st, mean_tbc, type = 'Exp', seed = 0):\n",
    "    np.random.seed(seed)\n",
    "    u1 = np.random.uniform(0,1, customers)\n",
    "    u2 = np.random.uniform(0,1, customers)\n",
    "    server_time = np.zeros(nserver)\n",
    "    time = 0\n",
    "    blocked = 0\n",
    "    if type == 'Exp':\n",
    "        arrival_times = getExp(lam = mean_tbc, us = u1)\n",
    "    elif type == 'Hyp':\n",
    "        arrival_times = getHyperExp(0.8, 0.8333, 5, u1, u2)\n",
    "    for i in range(customers):\n",
    "        delta_arrival_time = arrival_times[i]\n",
    "        time += delta_arrival_time\n",
    "        min_server = np.min(server_time)\n",
    "        idx_min_server = np.argmin(server_time)\n",
    "        if time < min_server:\n",
    "            blocked += 1\n",
    "        else:\n",
    "            server_time[idx_min_server] = time + stats.expon.rvs(scale = mean_st, size = 1)\n",
    "    \n",
    "    return blocked/customers\n",
    "\n",
    "nserver = 10\n",
    "mean_st = 8\n",
    "mean_tbc = 1\n",
    "customers = 10000\n",
    "nsim = 10\n",
    "runs = []\n",
    "for i in range(10):\n",
    "    runs.append([simulate_queue_q2(nserver, customers, mean_st, mean_tbc, 'Hyp', i), simulate_queue_q2(nserver, customers, mean_st, mean_tbc, 'Exp', i)])\n",
    "\n",
    "runs = np.array(runs)\n",
    "stats.ttest_rel(runs[:,0], runs[:,1]), np.mean(runs[:,0] - runs[:,1])*np.sqrt(10)/np.std(runs[:,0] - runs[:,1], ddof = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# q7 - montecarlo on standard normal random variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crude method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.022609, 0.02290035580710304, 0.02231764419289696)\n",
      "0.022609 0.02275013194817921\n"
     ]
    }
   ],
   "source": [
    "a = 2\n",
    "tot = 1000000\n",
    "values = np.random.randn(tot) > a\n",
    "res = np.mean(values)\n",
    "print(getCI(values))\n",
    "print(res, 1 - stats.norm.cdf(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importance sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importance sampling reduces the amount of samples required to estimate the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022382897015648693 0.02275013194817921\n"
     ]
    }
   ],
   "source": [
    "a = 2\n",
    "s = 1\n",
    "tot = 10000\n",
    "\n",
    "samples = stats.norm.rvs(loc = a, scale = s, size = tot)\n",
    "\n",
    "h = samples > a\n",
    "f = stats.norm.pdf(samples)\n",
    "g = stats.norm.pdf(samples, loc = a, scale = s)\n",
    "\n",
    "Z = h * f / g\n",
    "res = np.mean(Z)\n",
    "\n",
    "#print(getCI(Z))\n",
    "print(res, 1 - stats.norm.cdf(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# q8 - exponential importance sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.135220056680228, 1.7224825530121732)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam = 1.35483\n",
    "size = 100000\n",
    "values = stats.expon.rvs(scale = 1/lam, size = size)\n",
    "f = np.logical_and(values <= 1, values>=0)\n",
    "h = np.exp(values)\n",
    "g = lam*np.exp(-lam*values)\n",
    "\n",
    "res = f * h / g\n",
    "np.var(res), np.mean(res)\n",
    "\n",
    "# equal to the analytical solution (see photos on phone, done on paper)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# q9 - pareto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21.000000000000075, 20.999999999999982)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 1.05\n",
    "size = 10000\n",
    "values = stats.pareto.rvs(k-1, size = size)\n",
    "\n",
    "h = values\n",
    "f = stats.pareto.pdf(values, k)\n",
    "g = stats.pareto.pdf(values, k-1)\n",
    "\n",
    "res = h * f / g\n",
    "np.mean(res), k/(k-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
